{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4IPrtqZCqzcJLZ7hTH/H9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayuresh-tungare/upgrad_bootcamp/blob/main/module9/module9_graded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impact of Pricing on User Engagement\n",
        "\n",
        "You are a data analyst at an e-commerce platform that revises its product pricing and promotional strategies every two weeks. To make informed decisions, the company wishes to understand how product prices influence customer engagement on the platform.\n",
        "\n",
        "\n",
        "Your goal is to examine whether there is a strong, weak, or neutral relationship between product price and average time spent by the customer on the corresponding product page.\n",
        "\n",
        "\n",
        "Your task is to define a function analyze_price_time_relation(data) that accepts product prices and average time spent by customers on each corresponding product pages, calculates the correlation between product prices and time spent, and returns one of the following based on the correlation:\n",
        "\n",
        "\n",
        "'Strong' – if the absolute correlation is ≥ 0.7\n",
        "'Weak'– if the absolute correlation is between 0.3 and 0.7\n",
        "'Neutral'– if the absolute correlation is < 0.3\n",
        "\n",
        "Input Format\n",
        "\n",
        "\n",
        "A tuple of two tuples:\n",
        "\n",
        "\n",
        "product_prices: The first tuple includes product prices (float)\n",
        "\n",
        "time_spent: The second tuple includes the average time (float) spent by customers on each respective product page\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "\n",
        "A single value (str) indicating the strength of the relationship between product price and time spent\n",
        "\n",
        "Constraints\n",
        "\n",
        "N/A\n",
        "\n",
        "\n",
        "Example Case 1  \n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "((100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750), (2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5))\n",
        "\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "Strong\n",
        "\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "((100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150, 155, 160, 165),    (5.0, 5.1, 5.2, 5.1, 5.0, 5.1, 5.2, 5.0, 5.1, 5.2, 5.0, 5.1, 5.2, 5.0))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "Neutral"
      ],
      "metadata": {
        "id": "yWUvosC6DMUF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXarMOBz0As8"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "def analyze_price_time_relation(data):\n",
        "    # Code here\n",
        "\n",
        "    #unpack tuple\n",
        "    price, time = data\n",
        "\n",
        "    # calculate mean of product prices\n",
        "    avg_price = sum (price) / len (price)\n",
        "    avg_time = sum (time) / len (time)\n",
        "    n = len(price)\n",
        "\n",
        "    # Calculate Pearson correlation coefficient manually\n",
        "    numerator = 0.0\n",
        "    prices_denom = 0.0\n",
        "    time_denom = 0.0\n",
        "\n",
        "    for i in range(n):\n",
        "        price_dev = price[i] - avg_price\n",
        "        time_dev = time[i] - avg_time\n",
        "\n",
        "        numerator += price_dev * time_dev\n",
        "        prices_denom += price_dev ** 2\n",
        "        time_denom += time_dev ** 2\n",
        "\n",
        "    denominator = (prices_denom * time_denom) ** 0.5\n",
        "\n",
        "    if denominator == 0:\n",
        "        correlation = 0.0\n",
        "    else:\n",
        "        correlation = numerator / denominator\n",
        "\n",
        "    abs_correlation = abs(correlation)\n",
        "\n",
        "    # Determine relationship strength\n",
        "    if abs_correlation >= 0.7:\n",
        "        return 'Strong'\n",
        "    elif abs_correlation >= 0.3:\n",
        "        return 'Weak'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# (do not edit)\n",
        "print(analyze_price_time_relation(literal_eval(input())))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Portfolio Risk Analysis\n",
        "\n",
        "You are a quantitative analyst at a major investment firm. Your primary role involves assessing the risk associated with various financial portfolios. A key aspect of risk analysis is understanding the volatility of returns, which is quantified by measures of variability. The higher the variability, the higher the perceived risk.\n",
        "\n",
        "\n",
        "You are given a series of daily percentage returns for a specific investment portfolio over a period. Your task is to calculate two critical risk metrics: the Population Variance and the Population Standard Deviation of these daily returns. Additionally, you need to determine if the portfolio's volatility exceeds predefined acceptable thresholds for both metrics.\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "A tuple containing three elements:\n",
        "\n",
        "\n",
        "A list of daily percentage returns (float or int) for the portfolio\n",
        "\n",
        "A positive float specifying the acceptable variance threshold\n",
        "\n",
        "A positive float specifying the acceptable standard deviation threshold\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "The function returns a string describing the portfolio's risk level:\n",
        "\n",
        "\n",
        "'High Risk: Exceeds Both Thresholds' – if both variance and standard deviation exceed their thresholds\n",
        "'Moderate Risk: High Variance Only' – if only variance exceeds its threshold\n",
        "'Moderate Risk: High Standard Deviation Only' – if only standard deviation exceeds its threshold\n",
        "'Low Risk: Within Acceptable Limits' – if neither exceeds the\n",
        "\n",
        "Constraints\n",
        "\n",
        "The daily_returns list contains at least 2 return value\n",
        "If the list contains only 1 return value, the variance and standard deviation are treated as 0, and the portfolio will be classified as 'Low Risk: Within Acceptable Limits'.\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "([0.02, -0.01, 0.03, 0.05, -0.02, 0.01], 0.0005, 0.02)\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "High Risk: Exceeds Both Thresholds\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "([0.001, 0.002, 0.0015, 0.0025, 0.001], 0.0001, 0.01)\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "Low Risk: Within Acceptable Limits"
      ],
      "metadata": {
        "id": "2ML-mnHscDCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "# Function to calculate portfolio risk\n",
        "def analyze_portfolio_risk(data):\n",
        "    # Code here\n",
        "    daily_returns, variance_threshold, std_dev_threshold = data\n",
        "    avg_return = sum(daily_returns) / len(daily_returns)\n",
        "    variance = 0\n",
        "\n",
        "    for item in daily_returns:\n",
        "        variance = variance + abs(item - avg_return) ** 2\n",
        "    variance = variance / len(daily_returns)\n",
        "    std_deviation = (variance) ** 0.5\n",
        "\n",
        "    variance_exceeds = variance > variance_threshold\n",
        "    std_dev_exceeds = std_deviation > std_dev_threshold\n",
        "\n",
        "    if variance_exceeds and std_dev_exceeds:\n",
        "        return 'High Risk: Exceeds Both Thresholds'\n",
        "    elif variance_exceeds:\n",
        "        return 'Moderate Risk: High Variance Only'\n",
        "    elif std_dev_exceeds:\n",
        "        return 'Moderate Risk: High Standard Deviation Only'\n",
        "    else:\n",
        "        return 'Low Risk: Within Acceptable Limits'\n",
        "\n",
        "# Taking the input as a tuple (do not edit)\n",
        "# Format: (daily_returns, variance_threshold, std_dev_threshold)\n",
        "data = literal_eval(input())\n",
        "\n",
        "# Calculate and output the risk status\n",
        "print(analyze_portfolio_risk(data))\n"
      ],
      "metadata": {
        "id": "60p0s6m_ByPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding Student Activity Patterns\n",
        "You work as a data analyst at Edurise, an ed-tech company offering competitive exam coaching. The product team is aiming to enhance personalised learning recommendations by studying weekly student engagement patterns. They are particularly interested in understanding if students who invest more time on the platform are also more likely to engage actively with practice questions.\n",
        "\n",
        "\n",
        "Your task is to define a function compute_covariance(data) that accepts the time spent on the platform by students as well as the questions attempted by students, and computes and returns the covariance between these two metrics\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "\n",
        "A tuple of two tuples, each containing 7 numerical values:\n",
        "\n",
        "\n",
        "The first tuple represents the time spent (in minutes) (int) on the platform each day in a week\n",
        "\n",
        "The second tuple represents the number of questions (int) attempted each day in a week\n",
        "\n",
        "\n",
        "Output Format\n",
        "\n",
        "\n",
        "A single value (float) representing the covariance between time spent on the platform and number of questions attempted\n",
        "\n",
        "Constraints\n",
        "\n",
        "\n",
        "The final result is rounded to 2 decimal places\n",
        "\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "((45, 59, 40, 35, 66, 79, 72), (29, 22, 33, 43, 48, 42, 50))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "58.49\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "((30, 35, 40, 38, 42, 45, 50), (60, 55, 50, 52, 48, 45, 40))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "-36.86"
      ],
      "metadata": {
        "id": "inSuUxleCIN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_covariance(data):\n",
        "    # Code here\n",
        "    time, question = data\n",
        "    mean_time = sum(time) / len(time)\n",
        "    mean_question = sum(question) / len(question)\n",
        "    covariance = 0.0\n",
        "\n",
        "    for i in range(len(time)):\n",
        "        for j in range(len(question)):\n",
        "            if j == i:\n",
        "                covariance = covariance + ((mean_time - time[i]) * (mean_question - question[j]))\n",
        "\n",
        "    covariance = covariance / len(time)\n",
        "    return covariance\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "from ast import literal_eval\n",
        "print(round(compute_covariance(literal_eval(input())), 2))"
      ],
      "metadata": {
        "id": "siRQD_zvkEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SLA Compliance Across Regions\n",
        "\n",
        "You are working with a support operations team that tracks customer wait times across multiple service regions. The team uses these wait times to measure how well each region complies with its Service Level Agreement (SLA).\n",
        "\n",
        "\n",
        "According to the SLA, the median wait time in any region should not exceed a specified threshold (in minutes). Your task is to identify all regions that fail to meet this SLA requirement.\n",
        "\n",
        "\n",
        "Write a function failing_regions(wait_data, sla) that computes the median wait time for each region and returns the names of regions where the median wait time is greater than the SLA threshold.\n",
        "\n",
        "\n",
        "Input Format\n",
        "\n",
        "\n",
        "A tuple with two elements:\n",
        "\n",
        "wait_data: A dictionary where each key is a region name (string) and each value is a list of wait times (float) in minutes\n",
        "sla: A value (float) representing the SLA threshold\n",
        "\n",
        "Output Format\n",
        "\n",
        "A list of region names (str) whose median wait time exceeds the SLA threshold, sorted in alphabetical order\n",
        "If all regions comply with the SLA, return the string 'All regions meet SLA'\n",
        "\n",
        "Constraints\n",
        "\n",
        "All wait time values are non-negative floats\n",
        "SLA threshold values are non-negative floats\n",
        "Round the median wait time to two decimal places before comparing it with the SLA threshold\n",
        "\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "(\n",
        "\n",
        "    {\n",
        "\n",
        "        \"North\": [5.0, 7.2, 6.8, 8.0, 9.1, 6.5, 7.0],\n",
        "\n",
        "        \"South\": [12.5, 13.0, 14.1, 15.2, 12.0, 14.8],\n",
        "\n",
        "        \"East\": [6.0, 6.1, 6.2, 6.3, 6.4, 6.5],\n",
        "\n",
        "        \"West\": [10.0, 10.5, 9.8, 11.2, 10.3]\n",
        "\n",
        "    },\n",
        "\n",
        "    10.0\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "[\"South\", \"West\"]\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "Input\n",
        "\n",
        "(\n",
        "\n",
        "    {\n",
        "\n",
        "        \"North\": [2.0, 2.5, 3.0, 3.5, 4.0],\n",
        "\n",
        "        \"South\": [9.9, 10.0, 10.1, 10.0, 10.2],\n",
        "\n",
        "        \"East\": [5.0, 5.5, 6.0, 5.5, 6.0],\n",
        "\n",
        "        \"West\": [7.0, 6.5, 7.5, 7.0, 6.8]\n",
        "\n",
        "    },\n",
        "\n",
        "    9.5\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "[\"South\"]"
      ],
      "metadata": {
        "id": "8YHAdQhkkTNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries (do not edit)\n",
        "from ast import literal_eval\n",
        "\n",
        "def failing_regions(wait_data, sla):\n",
        "    # Code here\n",
        "    failing = []\n",
        "    for region, times in sorted(wait_data.items()):\n",
        "        times_sorted = sorted(times)\n",
        "        n = len(times_sorted)\n",
        "        median = times_sorted[n//2] if n % 2 else (times_sorted[n//2-1] + times_sorted[n//2]) / 2\n",
        "        if round(median, 2) > sla:\n",
        "            failing.append(region)\n",
        "    return failing if failing else 'All regions meet SLA'\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(failing_regions(*literal_eval(input())))"
      ],
      "metadata": {
        "id": "MDOdS4ZAkaqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect Stress-Linked Sleep Patterns\n",
        "\n",
        "You are helping a wellness platform analyse data from wearable devices that track heart rate and sleep duration. The goal is to detect users whose heart rate is strongly negatively correlated with their sleep duration — a potential indicator of chronic stress or burnout.\n",
        "\n",
        "\n",
        "Each user’s wearable data consists of several daily records, where each record logs the average heart rate and corresponding sleep duration for that day.\n",
        "\n",
        "\n",
        "You have been asked to identify all users who show a strong negative correlation (≤ –0.70) between their heart rate and sleep duration. This correlation must be computed manually, without using any external libraries.\n",
        "\n",
        "\n",
        "Write a function find_stress_linked_users(user_data) that calculates the Pearson correlation coefficient between heart rate and sleep duration for each user and returns the names of users who show a strong negative correlation (≤ –0.70)\n",
        "\n",
        "Input Format\n",
        "\n",
        "A tuple of tuples, where each inner tuple contains:\n",
        "\n",
        "user_id: a string representing the user’s ID\n",
        "records: a list of tuples (float, float) representing daily records in the form (heart_rate, sleep_duration)\n",
        "Output Format\n",
        "\n",
        "A list of user IDs (str) whose rounded correlation coefficient is ≤ –0.70, sorted in alphabetical order\n",
        "If no such users exist, return the string 'No stress-linked patterns detected'\n",
        "\n",
        "Constraints\n",
        "\n",
        "All values are non-negative floats\n",
        "Round the final correlation to 2 decimal places before comparison\n",
        "\n",
        "Example Case 1\n",
        "\n",
        "Input\n",
        "\n",
        "(('U1', [(70, 6), (75, 6), (80, 6), (85, 6), (90, 6)]),\n",
        "\n",
        " ('U2', [(90, 4), (85, 5), (80, 6), (75, 7), (70, 8)]),\n",
        "\n",
        " ('U3', [(60, 7), (65, 7.1), (70, 7.2), (75, 7.3), (80, 7.4)]))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "['U2']\n",
        "\n",
        "\n",
        "\n",
        "Example Case 2\n",
        "\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "(('U1', [(70, 6), (75, 6.5), (80, 6), (85, 6.5), (90, 6)]),\n",
        "\n",
        " ('U2', [(90, 5), (90, 5), (90, 5), (90, 5), (90, 5)]),\n",
        "\n",
        " ('U3', [(60, 7), (65, 6.8), (70, 7.1), (75, 6.9), (80, 7)]))\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "\n",
        "No stress-linked patterns detected"
      ],
      "metadata": {
        "id": "2SlbeQhvlJPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries (do not edit)\n",
        "from ast import literal_eval\n",
        "\n",
        "def find_stress_linked_users(user_data):\n",
        "    # Code here\n",
        "    stress_users = []\n",
        "\n",
        "    for user_id, records in user_data:\n",
        "        if len(records) < 2:\n",
        "            continue\n",
        "\n",
        "        heart_rates = [record[0] for record in records]\n",
        "        sleep_durations = [record[1] for record in records]\n",
        "        n = len(records)\n",
        "\n",
        "        # Calculate sums for Pearson correlation formula\n",
        "        sum_x = sum(heart_rates)\n",
        "        sum_y = sum(sleep_durations)\n",
        "        sum_xy = sum(x * y for x, y in zip(heart_rates, sleep_durations))\n",
        "        sum_x2 = sum(x * x for x in heart_rates)\n",
        "        sum_y2 = sum(y * y for y in sleep_durations)\n",
        "\n",
        "        # Pearson correlation coefficient formula\n",
        "        numerator = n * sum_xy - sum_x * sum_y\n",
        "        denominator = (n * sum_x2 - sum_x ** 2) ** 0.5 * (n * sum_y2 - sum_y ** 2) ** 0.5\n",
        "\n",
        "        if denominator == 0:\n",
        "            continue\n",
        "\n",
        "        correlation = round(numerator / denominator, 2)\n",
        "\n",
        "        if correlation <= -0.70:\n",
        "            stress_users.append(user_id)\n",
        "\n",
        "    if not stress_users:\n",
        "        return 'No stress-linked patterns detected'\n",
        "\n",
        "    return sorted(stress_users)\n",
        "\n",
        "# Input and output processing (do not edit)\n",
        "print(find_stress_linked_users(literal_eval(input())))"
      ],
      "metadata": {
        "id": "cF1KXNpslWiz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}